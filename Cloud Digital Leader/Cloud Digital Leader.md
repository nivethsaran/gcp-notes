# Cloud Digital Leader

# Course 1

[https://www.notion.so](https://www.notion.so)

### Module 1 - Why Cloud Technology is Revolutionizing Business

- Inventions throughout history triggered thousands of innovations
in what are called “Kondratiev waves” or “innovation waves.”
- These waves increase in both supply and demand (eg electricity) (note: they are irreversible too)
- We’re right in the middle of another paradigm shift. Cloud technology is transforming how businesses create value, how people work, and ultimately how people live.
- The cloud is a metaphor for the network of data centers which store and compute information available through the internet.
- When an organization takes advantage of new technologies such as cloud to redesign and redefine relationships with their customers, employees, and partners the result is a companywide digital transformation.
- Cloud enables each of the above in every industry and for every activity.
    - Collaborate
    - Perceive
    - Categorize
    - Predict
    - Recommend
- Abandoning old technology for a new one is commonly referred to as the “**burning platform**” effect. It requires organizations to take a leap of faith and to continually adapt as new technologies create new paradigm shifts.
- **Successful companies consistently focus on “why” they exist, not “how” they operate. (Nintendo vs Encyclopedia Comparison)**
- The power of cloud also changes the way we work by automating processes and enabling real-time collaboration between people globally.
- Should understand what cloud is and the basic terminologies
- What is computing?
    - **Computing** is the **ability** to process **information** and **automate** tasks most often done by a computer program.
    - **Compute power**, refers to the **speed** at which a computer is able to **process** data.
- The first disruption comes from processors that are specifically meant for this type of application, and which we call **TPUs**, for Tensorflow Processing Units. They are **50** times more powerful than traditional chips!
- The second disruption comes from **quantum computing**, which is a **hundred million** times more powerful.
- Computing will mainly be generated in plants, which are the data centers, and accessed through a grid, which is the internet.
- Traditional computing is about taking a piece of information—an input— through an algorithm in order to get an output, while Cloud computing geenrates trained algo using both input and output (Basically ML in cloud)
- Cloud gives both large and small companies to scale

---

### Module 2 - Digital Transformation with Google Cloud

- As consumer expectations change, business models must adapt to remain relevant. The traditional advantages of size and scale are no longer as differentiating as they used to be.
- Orgs now need to be
    - Innovative,
    - Agile,
    - Fast,
    - Customer-focused.
- The culture of an organization has a direct impact on employees’ willingness to innovate. Innovation relies on people being able to try things and failing without judgement.
- How teams are structured, how content is managed, and how communication flows across an organization are all elements that impact innovation.
- Three core focus areas for modernization
    - Infrastructure
        - Infrastructure Do not distribute ‘Infrastructure modernization’ is a common term used to describe the process of replacing legacy hardware and systems and consolidating them in the cloud.
        - Most organizations want to operate a hybrid model. This means operating across multiple cloud providers or one cloud provider combined with some on premises solutions.
        - Businesses can take advantage of high performance computing in a cost effective and scalable way.
        - With cloud computing, businesses can scale in the cloud and pay for what they use, when they use it.
    - Business Platforms
        - Business application platforms enable integration between systems and granting users the correct access privileges in an organization and beyond.
        - What is an API - Application Processing Interfaces (Enables integrations)
    - Applications
        - What is an application - Programs and software that performs digital tasks
        - Today’s customers expect instant access to services wherever they are. An organization’s ability to develop and launch applications is central to their success in today’s competitive market.
        - What is DevOps - DevOps, or Developer Relations, is a set of practices that aim to increase software delivery velocity, improve service reliability, and build shared ownership among software stakeholders.
- Data is no longer about only retrospective insight; rather, real-time insight, smart predictions, and intelligent action.
- With the right platform, organizations can generate instant insights from data at any scale.
- Traditionally, IT security models focused on keeping threats out. They built an on-premises perimeter that individuals required access to in order to gain entry. That model worked when all hardware and systems were controlled and managed centrally.
- Now, employees want to create, share and access information virtually. In an increasingly global workforce, businesses need to grant access to applications and relevant data with a high degree of security.
- Shared Responsibility Security Model - Cloud Provider manages business infra, companies manage access to data and resources
- Compliance with regional regulations is also part of security and governance. These regulations govern where data is stored and how it is managed.
- Google takes what it has learned from serving billions of users and creates Google Cloud products and solutions available to organizations around the world. Now, customers can build their own applications and manage their own workloads on that same infrastructure to achieve their mission and serve their users.
- Pillars of Google Cloud Solution
    - Infra modernization
        - Google Cloud and its partners offer flexible infrastructure modernization approaches from rehosting customer’s existing IT to replatforming.
        - Once companies have modernized their infrastructure with Google Cloud, they can then leverage the innovation built into Google Cloud’s technology to create new business value.
    - Business apps platform portfolio
        - With Google Cloud’s business application platforms portfolio, businesses can securely unlock their data with APIs, automating processes and creating applications across clouds and on-premises without coding.
    - Application Modernization
        - Businesses can better serve their users through application modernization. The tools within this pillar help businesses develop and run applications anywhere.
    - DB and Storage Solutions
        - Google Cloud’s database and storage solutions include tools that help businesses migrate and manage enterprise data with security, reliability, high availability, and fully managed data services.
    - Smart Analytics
        - The smart analytics portfolio helps businesses generate instant insights from data at any scale with a serverless, fully managed analytics platform.
    - AI
        - Google Cloud’s artificial intelligence tools are built to enhance innovation and improve productivity, by integrating seamlessly into a company’s existing workflow and products.
    - Security
        - Google Cloud’s comprehensive security solutions cover all aspects of protecting your business in this digital era. businesses are able to detect, investigate, and protect themselves against online threats before attacks result in damage or loss.
- To help organizations optimize their cloud adoption, Google developed the Google Cloud Adoption Framework. This best practice guide provides a framework to assess where an organization is in its journey and what they need to do next.
    
    [Adoption Framework | Google Cloud](http://cloud.google.com/adoption-framework)
    

---

### Module 3 - Scale the Innovation Mindset

- When you see cloud as a tool to do things the way you’ve always done them, you risk vanishing into irrelevance. Using cloud to do new, transformative things means embracing wholesale change.
- This change may involve radically rethinking business practices, structures, and even business models so you can better serve your customers globally.
- Core tenets to create a fast-moving, customer centric, future proof business using cloud technology.
    - Talent
        - Talent refers to a “holistic view” of the people that make up an organization. It covers the entire lifecycle from attracting, to hiring, to nurturing, to retaining, to celebrating, and growing the talent.
    - Environment
        - The ability of people to thrive in an organization–especially during major changes–is connected to their work environment.
    - Structure
        - Structure is a blueprint for how certain programs and tasks are grouped and how the people managing them are led toward a common goal.
    - Strategy
        - Strategy is how you align people to your organization’s purpose or mission.
    - Empowerment
        - Empowerment means enabling employees by giving them access to relevant information and encouraging them to use it to take initiative to solve problems and improve the business.
    - Innovation
        - Innovation is central to embracing new technology. Innovation is about doing something in a surprisingly new way, or discovering something entirely new that adds value.
        - Innovation, can’t be owned or ordained. But you can create the environment and right conditions for innovation to evolve organically.
- Three simple rules to nurture and scale a culture of innovation
    - Focus on the User
        - Who they are and what they expect
        - Narrow Down Scope of user expectations
            - Access
                - When it comes to access, users expect faster and easier services, with ‘always-on’ capabilities, that can be accessed anywhere.
            - Engagement
                - In terms of engagement, users are looking for sources of valued content. They expect up-to-date, reliable content from multiple fields of expertise.
            - Customization
                - When it comes to customization, users expect that a product or service seamlessly adapts to their individual needs and preferences.
            - Communication
                - Users expect to be able to communicate with service providers through a two-way feedback channel—this means that the company also engages in conversation.
    - Think 10x
        - 10X thinking is about generating big ideas. It’s about transformation over improvement and using technology to achieve that transformation. Improvement projects help make things better by perhaps 10%.
        - 10X thinking leads to solutions that are simple, empowering, and deeply transformative. Just like focusing on the user, thinking 10x helps organizations achieve their mission in new ways and to differentiate their offering from competitors.
    - Launch and iterate (Also known as continuous learning)
        - Launch and iterate is both a mindset and a practice where, instead of starting off with a perfect solution, you figure it out through experimentations.
- TEAM Psychological Safety
    - When people feel psychological safety and begin applying the launch and iterate rule into their day-to-day work the result is the prototyping effect. The more ideas you try, the more you learn, and the more you eventually succeed.
    - Ideas don’t have to be limited to hardware or service products. This way of thinking can also be used for any employee-customer or employee-employee interaction.
    - Embracing cloud technology and cultivating an innovative mindset are not limited to elite data scientists or company leaders. You can cultivate this mindset in your role, in your team, and across your organization, no matter where you are.
    

## Course 2

[https://www.notion.so](https://www.notion.so)

### Module 1 - The Value of Data

- What is data - self explanatory.
- Businesses now have a lot of access to data(new kinds of data)
- The internet has also enabled access to external data, such as industry benchmarking reports. Capturing and leveraging this data to unlock business value is central to digital transformation.
- Large enterprises with traditional IT infrastructures face several limitations when it comes to leveraging the value of data. These limitations include: processing volumes and varieties of new data, finding cost effective solutions, scaling resource capacity up or down, accessing historical data, and deriving insights from historical and new data.
- Google Cloud offers
    - Economies of Scale
    - Automation
    - Rapid elasticity
    - Data Access
- Businesses can now consume, store and process terabytes of data in real-time, and run queries—that is, requests to retrieve and use data, instantly.
- Resources are now distributed across a global network. Multiple data centers create resilience against data loss or service disruption, without any extra overhead for businesses. And data can be combined, analyzed and served to business teams quickly and cost effectively.
- A “data map” is a chart of all the data used in end-to-end business processes.
- Three types of data
    - Structured - RDBMS for instance
    - Unstructured - Audio, Video etc
        - Can be stored as **B**inary **L**arge **Ob**ject(BLOB)
        - Difficult to analyse
    - Semi Stuctured - JSON, XML etc
- Handling volumes and diversity of data comes with its own ethical considerations and requires alternative ways of thinking about security. Not all information that can be captured, should be captured. Businesses are accountable for making responsible decisions about which data they collect, store, and analyze.
    - If it’s personal or sensitive data about a customer or an employee, it needs to be securely collected, encrypted when stored in the cloud, and protected from external threats.
    - Regional or industry specific regulations often guide data policies. Do not distribute
    - Ethical and fair considerations are particularly important and applicable when you work with Artificial Intelligence (AI) and Machine Learning.
- Human bias can influence the way datasets are collected, combined, and used. It’s always important to include strategies to remove unconscious biases as you start to leverage data to build new business value.

---

### Module 2 - Data Consolidation And Analytics

- If you’re storing your data on-premises, you’ll need to start thinking about taking some or all of it to the “bank”—in other words, the cloud. It will provide a greater return on investment.
- When you store your data on-premises, you are responsible for the IT infrastructure that supports the collection, security, and processing of that data. You’re also responsible for maintaining and expanding the capacity of your IT infrastructure.
- With cloud, you can ‘rent’ space from public cloud providers like Google Cloud. This means that their data storage and compute power is elastic.
- Another way that migrating data to the cloud provides a better return on investment is the speed at which you can ingest and use data. Businesses can now ingest data in real-time.
- Data Management Prioriities
    - Data Integrity
        - Data integrity, or transactional integrity, refers to the accuracy and consistency of data stored in a database. Data integrity is achieved by implementing a set of rules when a database is first designed and through ongoing error checking and validation routines as data is collected.
        - Databases also allow businesses to rollback transactions to see data history.
    - Scale
- **Cloud SQL**
    - It’s a fully managed relational database management service, or RDBMS. It easily integrates with existing applications and Google Cloud services like Google Kubernetes Engine and BigQuery.
    - Cloud SQL offers security, availability and durability, and storage scales up automatically when enabled.
- **Cloud Spanner**
    - It’s another fully managed database service, and it’s designed for global scale. With Cloud Spanner, data is automatically and instantly copied across regions. This replication means that if one region goes offline, the organization’s data can still be retrieved from another region.
    - With Google Cloud databases, businesses can build and deploy faster, deliver transformative applications, and maintain portability and control of their data.
- **Difference between Database and Data Warehouse**

- While databases store transactional data in an online fashion,
- Databases are built and optimized to enable ingesting large amounts of data from many different sources efficiently. However,

- data warehouses assemble data from multiple sources including databases.
- data warehouses are built to enable rapid analysis of large and multi-dimensional datasets.
- Think of the data warehouse as the central hub for all business data. Different types of data can be transformed and consolidated into the warehouse so that they are useful for analysis.
- In particular, a cloud data warehouse allows businesses to consolidate data that is structured and semi-structured.
- When combined with connector tools, data warehouses can transform unstructured data into semi-structured data that can be used for analysis.
- Most data warehouse providers link storage and compute together, so customers are charged for compute capacity whether they are running a query or not.
- **Big Query**
    - BigQuery is serverless. This doesn’t mean that there’s no server!
    - It means that resources, such as compute power, are automatically provisioned behind the scenes as needed to run your queries. So businesses do not pay for compute power unless they are actually running a query.
    - Pub/Sub and DataFlow can work together to bring unstructured data into the cloud and transform it into semi-structured data.
    - This transformed data can then be sent directly from Dataflow to BigQuery, where it is made immediately available for analysis.
- **Data Lake**
    - Data lakes are a repository for raw data and tend to serve many purposes.
    - They often hold 'back-up' data, which helps businesses build resilience against unexpected harm affecting their data. Businesses are protected against data loss. They also hold data that is historic and not relevant to day-to-day business operations.
    - One way to classify an organization’s requirements for storage is by how often they need to access the data.
- **Cloud Storage Benefits**
    - Any amount of data
    - Low latency
    - Accesible from anywhere
- Cloud Storage offers multi-regional storage. It’s ideal for serving content to users worldwide.
- Regional storage offered by Cloud Storage is ideal when an organization wants to use the data locally; it gives added throughput and performance by storing data in the same region as your compute infrastructure.
- For data that will be accessed less often, Cloud Storage offers Nearline, Coldline and Archive storage classes.
- The challenge businesses often face is identifying the right business intelligence solution. Some solutions are too complex and not accessible by anyone outside the data engineering or data analysis teams.
- Other solutions let everyone in the business perform their own data analysis. But they can only perform their analysis with portions of the available data. This means that only a few people, or possibly no one, has a full view of the company’s business data.
- Looker
    - Looker is a Google Cloud business intelligence solution. It’s a data platform that sits on top of any analytics database and makes it simple to describe your data and define business metrics.
    - Once you have a reliable source of truth for your business data, anyone on your team can analyse and explore it, ask and answer their own questions, create visualisations, and explore row level details.

---

### Module 3 - Innovation with ML

- What is AI and ML - Self
- Algo → Data → Predictive Insight → Decision
- Bugs in ML are often caused by bugs in the data. In traditional software development, a bug is a mistake in the code that causes unexpected or undesired behavior. In ML, even though there can be bugs in the implementation of an algorithm, bugs in data are far more common.
- Data Cleanliness and Data Completeness - Self
- Both the above factors can affect the model accuracy and output
- Google Cloud democratizes AI by providing a range of ML and AI solutions that enable businesses to leverage the power of ML and AI, without the traditional costs and efforts.
- TensorFlow has a comprehensive, flexible ecosystem of tools, libraries and community resources. TensorFlow lets researchers push innovations in ML and developers to easily build and deploy ML powered applications.
- TensorFlow takes advantage of Tensor Processing Units (TPU), hardware devices designed to accelerate ML workloads with TensorFlow by 15-30x. Because you pay only for what you use, there’s no up-front capital investment required.
- The AI Hub is a hosted repository of plug-and-play AI components, including end-to-end AI pipelines and out-of-the-box algorithms.
- APIs are simple methods and tools to connect various applications. They can be deployed in a virtual private cloud, on-premises, or in Google’s public cloud. They allow developers to quickly and easily train custom models regardless of their level of ML experience.
- Business Problems ML would solve
    - Replacing rule-based systems
    - Automation
    - Understanding unstructured data
    - Personalizing applications

---

---

# Course 3

### Module 1 - Modernizing IT Infra with GCP

- Central to an organization’s ability to thrive in the new era is the way in which they structure and use their IT resources. This could mean moving away from investing resources to run and maintain existing IT infrastructure.
- Leveraging cloud technology to truly transform a business requires new collaborative models, changing culture and processes, and enabling team productivity and innovation.
- Enterprises are seeing significant financial benefits from adopting cloud, as their approach to IT moves from buying fixed capacity to paying only for what they use.
- Owning and operating infrastructure limits an organization’s staff in several ways: They have to undertake laborious tasks related to infrastructure, they are using legacy systems that are old, and they cannot scale with any ease.
- The first step in moving away from an on-premises infrastructure is colocation. A business sets up a large data center and then other organizations rent part of that data center.
- This means organizations no longer have to pay the costs associated with hosting the infrastructure, but they still need to pay to maintain it.
- Hardware is often heavily under utilized, even in the colocation model, so engineers packaged applications and their operating systems into a virtual machine.
- Virtual Machines
    - Virtual machines share and optimize the same pool of computer processing, storage, and networking resources. They also enable businesses to have multiple applications running at the same time on a server.
    - There’s still a cap to the physical capacity of existing servers and companies still have to commit a substantial amount of capital expenditure upfront.
- Many companies are now outsourcing their infrastructure entirely. They are growing to deliver their products and services to customers regionally and globally, and need to scale quickly and securely. Setting up and maintaining data centers and network connections that are optimal for their needs is expensive.
- **IAAS**
    - Outsourcing your IT needs at the infrastructure level is called infrastructure as a service. If your organization chooses to, it can move some or all of its infrastructure away from physical data centers to virtualized data centers in the cloud.
    - The maintenance work is outsourced to the public cloud provider so it’s easier to shift a larger proportion of company expertise to build processes and applications that move the business forward.
- PAAS
    - If you want a more managed service, cloud service providers offer something called: platform as a service. In this case, you don’t have to manage the infrastructure and for some services you only pay for what you use.
- Traditionally, the hardware available for computing could only run a limited amount of software and applications. But with virtual machines or ‘VMs’, multiple systems can now run on the same hardware. VMs share the same pool of computer processing, storage, and networking resources.
- The software layer that enables this is called a hypervisor. A hypervisor sits on top of physical hardware, and multiple VMs are built on top of it. It’s like having multiple computers that only use one piece of hardware.

![Untitled](Cloud%20Digi%2068a8f/Untitled.png)

- Virtual machines recreate a full representation of the hardware. Containers only recreate, or virtualize, the operating systems.

![Untitled](Cloud%20Digi%2068a8f/Untitled%201.png)

- Containers only hold exactly what’s needed for the particular application that they support. They start faster, use less memory, and allow developers to create predictable environments.
- Containers are like prefabricated units placed on top of each other. This means that any problem that arises is easier to isolate and fix.

![Untitled](Cloud%20Digi%2068a8f/Untitled%202.png)

- **FAAS -Function As A Service**
    - Serverless computing means that resources, such as compute power, are automatically provisioned behind-the-scenes as needed. Businesses do not pay for compute power unless they are actually running a query or application.
    - Serverless computing solutions are often called ‘Function-as-a -service.’ Businesses provide the code for whatever function they want and the public cloud provider does everything else.
- Private Cloud
    - Private cloud is where an organization has virtualized servers in its own data centers to create its own private on-premises environment. This might be done when an organization has already made significant investments in its own infrastructure, or if, for regulatory reasons, data needs to be kept on-premises.
- Hybrid Cloud
    - Hybrid cloud is where an organization is using a combination of on-premises or private cloud infrastructure and public cloud services. Some data and applications have been migrated to the cloud and others remain on premises.
- Multi Cloud
    - Multi-cloud is where an organization is using multiple public cloud providers as part of its architecture. The organization needs flexibility and secure connectivity between the different networks involved.
- Open source in the cloud preserves an organization’s control over where they deploy their IT investments.

 

![Coming Up Next](Cloud%20Digi%2068a8f/Untitled%203.png)

Coming Up Next

- Compute Engine
    - Compute Engine is a computing and hosting service that lets you create and run virtual machines on Google infrastructure.
    - Compute Engine VMs boot quickly, come with persistent disk storage, and deliver consistent performance.
- Cloud VMWare
    - Google Cloud VMware Engine is a fully managed service that lets you run the VMware platform in Google Cloud. Google manages the infrastructure, networking and management services.
- Bare Metal
    - Bare Metal enables you to migrate specialized workloads to the cloud, while maintaining your existing investments and architecture. This allows you access and integration with Google Cloud services with minimal latency.
- Google Kubernetes
    - Google Kubernetes Engine or GKE provides a managed environment for deploying, managing, and scaling your containerized applications using Google infrastructure. The GKE environment consists of multiple machines grouped together to form a cluster.
    - GKE allows you to securely speed up app development, streamline operations, and manage infrastructure.
- Google App Engine
    - Google App Engine is a Platform as a Service and cloud computing platform for developing and hosting web applications. It lets app developers build scalable web and mobile back ends in any programming language on a fully managed serverless platform.
- Cloud Run
    - Cloud Run allows you to build applications in your favorite programming language, with your favorite dependencies and tools, and deploy them in seconds. It abstracts away all infrastructure management by automatically scaling up and down from zero almost instantaneously—depending on traffic.
- Cloud Function
    - Cloud Functions is a serverless execution environment for building and connecting cloud services. It offers scalable, pay-as-you-go functions as a service to run your code with zero server management.

---

### Module 2 - Modernizing Applications with GCP

- Google Cloud has identified five common patterns that businesses can adopt when they want to modernize their applications.
    - Move applications first and then change them
        - The “move first and then change” approach typically starts with a “lift and shift” program for selected applications. The migration typically brings minimal changes to ways of working within the organization, but once the applications are running in the cloud, they are then ready to be updated more easily than when they were running on-premises.
    - Change applications before they move
        - If an organization wants to take a more aggressive approach to modernizing its applications, they can re-architect applications first, to make them more cloud-ready, before migrating them.
    - Invent in greenfield
        - Inventing in greenfield allows you to build innovative applications that will help drive the business forward, but it does require agility, access to a diverse development skill set, and strong support from leadership.
    - Invent in brownfield
        - A brownfield strategy is to invent a new application in the cloud environment that will replace an existing legacy application that remains on-premises. The legacy application is only retired after the new application is built.
    - Move applications without any changes
        - For some use cases, it’s sufficient to leverage the cloud just to modernize the infrastructure layer. Use cases include switching to cloud storage to decommission on-premises data centers, or creating virtualized environments for disaster recovery.
- New applications often have to be designed, built, tested, integrated, and deployed. But new needs often compete with existing projects for time and resources.
- Developing cloud-native applications avoids the hassle of trying to create something that is constrained by legacy systems and out-dated processes. Building a new application in the cloud frees teams up from worrying about environments so that they can focus on creating features instead.
- Updating existing applications that have been built on-premises with a monolithic architecture can be difficult. When an application is updated, the entire application needs to be deployed and tested, even if the change is only small.
- A microservice architecture reduces these problems by separating a large application into small, loosely coupled services. This means it’s easy to determine where code needs to be changed and the service can be updated, deployed, and scaled independently.
- Adopting an automated continuous integration or ‘CI/CD’ can help you increase your application release velocity and reliability. You can test and roll out changes incrementally. This approach enables you to lower the risk of regressions, debug issues quickly, and roll back to the last stable build if necessary-- all without interrupting service for your users.
- Containerization allows developers App App App to divide an application design into individual compartments. Parts of the code can be updated without affecting the whole application. This builds resilience, because one error doesn’t impact the whole application.

![Untitled](Cloud%20Digi%2068a8f/Untitled%204.png)

- Kubernetes
    - Kubernetes is an open-source container-orchestration system for automating computer application deployment, scaling, and management.
    - Google Kubernetes Engine or GKE, is the Google Cloud managed service for container orchestration. GKE enables rapid application development and iteration by making it easy to deploy, update, and manage your applications and services.
- Serverless computing can be used for application development. You write the code for the functions you want, and the cloud provider updates and adapts the containers or VMs as needed.
- App Engine
    - App Engine is a platform for building scalable web applications and mobile backends. App Engine will scale your application automatically in response to the amount of traffic it receives, so you only pay for the resources you use.
    - You can easily run multiple versions of your app to test new features or designs with end users. Because there are no servers for you to provision or maintain, the monitoring and maintenance processes are easier too.

---

### Module 3 - The Value of APIs

- Legacy systems and applications are complex, expensive to maintain, and do not provide the speed and scale required to deliver seamless, digital experiences that consumers now expect.
- Legacy System
    - A legacy system is outdated computing software and/or hardware that is still in use. The legacy system is mission critical but often not equipped to deliver new services or upgrades at the speed and scale that users expect. A legacy system often can't connect to newer systems.
- Legacy systems weren’t developed to support the implementation and adoption of modern technologies, such as the cloud, or the internet of things, or mobile applications.
- They were also developed for a time when data was shared in batches or at specific time intervals.
- Legacy systems are not designed to serve real-time data as is expected in today’s digital world. As a result, legacy systems tend to hold organizations back from using digital technologies to innovate or improve IT efficiency.
- An API is a piece of software that connects different applications and enables information to flow between systems, so businesses can unlock value and create new services. They expose data in a way that protects the integrity of the legacy systems and enables secure and governed access to the underlying data.
- Web or mobile apps are built by internal enterprise developers or by external third-party companies. APIs are built and managed by the API Team within the enterprise. App developers leverage those APIs to integrate with backend services and other service endpoints.

![Untitled](Cloud%20Digi%2068a8f/Untitled%205.png)

- A digital ecosystem is a group of interconnected companies and products. This includes vendors, third party suppliers, customers, and applications. A robust, well connected, and multi faceted digital ecosystem enables businesses to create and monetize new digital experiences.
- The more you know about your customers, the better able you are to offer a truly integrated, end-to-end digital experience.
- Legacy systems provide business data but don’t provide features and capabilities at the rate of change demanded by today’s users. Modern applications provide connected experiences and can be rapidly updated to meet user demands.
- Developers need to manage the entire application lifecycle, connect to different backend systems—including legacy ones—and be able to track and analyze the interactions between consumers and data and service producers.

![Untitled](Cloud%20Digi%2068a8f/Untitled%206.png)

![Untitled](Cloud%20Digi%2068a8f/Untitled%207.png)

![Untitled](Cloud%20Digi%2068a8f/Untitled%208.png)

![Untitled](Cloud%20Digi%2068a8f/Untitled%209.png)

- Legacy systems provide business data but don’t provide features and capabilities at the rate of change demanded by today’s users. Modern applications provide connected experiences and can be rapidly updated to meet user demands.
- Developers need to manage the entire application lifecycle, connect to different backend systems—including legacy ones—and be able to track and analyze the interactions between consumers and data and service producers.
- As a company’s digital ecosystem becomes more complex, the required time and effort to manage 100s of APIs securely and at scale becomes costly.
- Apigee is a fully featured API management platform that enables application developers and API providers to create connected digital experiences for end users. Apigee bridges the gap between legacy systems.
- The Apigee platform includes API services that provide the runtime API gateway functionality, Developer Services that allow developers to utilize their APIs, and Analytics Services that enable enterprises to report on APIs.

![Untitled](Cloud%20Digi%2068a8f/Untitled%2010.png)

---

# Course 3 - Understanding Google Cloud Security and Operations

### Module 1 - Financial Governance in the Cloud

- Cloud technology can provide organizations with the means to make more dynamic decisions and accelerate innovation, but managing cloud costs requires vigilance and real-time monitoring in parallel.
- Because almost anyone can now access cloud resources on-demand, it involves more people across multiple teams.
- For organizations that build and deploy applications on-premises, there’s a heavy emphasis on capital expenditure to set up and maintain their IT infrastructure. It’s a careful balancing act between under-purchasing and over-purchasing, so a business doesn’t end up with unserved demand or wasted capacity.
- When an organization migrates or builds and deploys applications using cloud services, there’s a greater emphasis on operational expenditure. They’re paying for what they need when they need it.
- Budgeting is no longer a one-time operational process completed annually. Because of the variable nature of cloud resources and their costs, spending must be monitored and controlled on an ongoing basis.
- Given the right permissions, almost any employee can spin up resources in seconds. Often, the accessibility that makes cloud services attractive leads to reduced control and significant overspending.
- When cloud usage isn’t effectively controlled, it can lead to inefficiencies. According to a Rightscale study from Flexera, businesses surveyed estimated they were wasting 27% of their cloud spend. Businesses were actually wasting 35% of their cloud spend: 8% over their estimates.
- In a small organization, there might be one person or team responsible for managing all aspects of the cloud infrastructure and associated finances, from budgeting to procurement, tracking, optimization, and so on.
- In large organizations, there are people involved across multiple functions. Technology and line-of-business teams are often using cloud resources, but they don’t necessarily factor cost into their decision-making. Finance teams control cloud costs, but may struggle to understand or to keep up with cloud spend on a daily, weekly, or monthly basis.
- Three ways to solve the above mentioned problem
    - People
        - To manage cloud costs effectively, a partnership across finance, technology, and business functions is required. This partnership would consist of several experts who ensure that best practices are in place across the organization and there is visibility into the ongoing cloud spend.
    - Process - When it comes to cloud cost management, consider the following questions:
        - What cloud resources are being used and by whom?
        - What are the associated resource costs?
        - How do these costs measure against the broader business strategy?
    - Technology
        - Google Cloud brings its own native tools to help organizations monitor and manage their costs. In fact, these tools enable organizations to gain greater visibility, drive a culture of accountability for cloud spending, control costs to reduce the risk of overspending, and provide intelligent recommendations to optimize costs and usage.
- Whether an organization is moving to the cloud for the first time or moving from a single cloud provider to multiple providers, how they calculate the total cost of ownership of the IT infrastructure will vary. Total cost of ownership varies with complexity

![Untitled](Cloud%20Digi%2068a8f/Untitled%2011.png)

- Historically, when companies spent a substantial amount of money upfront to set up their IT infrastructure, the capital expenditure would include paying for:
    - Space and associated costs
    - Storage systems
    - Networking
    - Hardware
    - Software
    - Security systems
- When organizations run their business using public cloud services, much of their capital expenditure shifts toward a pay-as-you-go OpEx model.
- Some organizations may choose to keep some of their business running on-premises and some running on public cloud. The total cost of ownership for them would be more complex.
- Best practices for Google Cloud tools ongoing cost management:
    - Identify the individual or team that will manage costs
    - Learn the difference between invoices and cost tools
    - Use cost management tools for accountability
- The goals of cost management tools are to provide
    - Visibility
        - Before organizations can optimize their cloud costs, they first need to understand what they’re currently spending, whether there are any trends, and what their forecasted costs are. This means they need visibility into their cloud costs.
        - A central team can monitor current cost trends and identify areas of waste that could be improved using Google Cloud built-in reporting tools, and create custom dashboards to gain greater visibility into their costs. The pricing calculator allows an organization to see how changing usage will affect their costs.
        - The below link has
            - Built in reporting tools
            - Custom dashboards
            - Pricing calculator
        
        [Google Cloud Pricing Calculator](http://cloud.google.com/products/calculator)
        
    - Accountability
        - Because cloud spending is decentralized and variable, it’s important to establish a culture of accountability for costs across the organization. This can be done by defining clear ownership for projects and sharing cost views with the departments and teams that are using cloud resources.
    - Control
        - Organizations should also have precise permissions in place to ensure that only authorized individuals in an organization have the power to deploy cloud resources. Creating budgets and alerts to notify key stakeholders when spending is getting off track is an important practice to keep costs under control.
    - Intelligence
        - Organizations can make smart spending decisions with intelligent recommendations delivered by Google Cloud. These are tailored to each organization and help optimize usage, save time on management, and minimize costs. The recommendations can easily be applied for immediate cost savings and greater efficiency.

---

### Module 2 - Security in the cloud

- Fundamental terms
    - Privacy
        - Privacy, in the context of cloud technology, refers to the data an organization or an individual has access to and who they can share that data.
        - When moving your data to the cloud, the facility and its employees only store or process your data. The data itself remains private.
    - Security
        - Security in the cloud refers to the policies, procedures, and controls put in place to keep data safe.
    - Compliance
        - Compliance is about meeting standards set by a third party. This third party might be a regulatory authority, or it might be an international standards organization.
        - Compliance is especially important in highly regulated industries—such as Healthcare or Finance—where there is an abundance of sensitive data.
    - Availability
        - It refers to how much time the cloud service provider guarantees data and services will be running or accessible.
        - The availability of a service is typically documented as a percentage of time per year. To assess the availability of a service, you might ask:
            - Does the system work
            - Am I confident that I can access my files anytime I need to, day or night?
            - Will I not have access due to system downtime?
- If you’re using, or plan to use Google Cloud products and services, Google Cloud’s commitment to helping you keep your data secure and private is as follows:
    - You own your data, not Google.
    - Google does not sell customer data to third parties
    - All customer data is encrypted by default
    - Google Cloud guards against insider access to your data
    - We never give any government entity “backdoor” access to your data
    - Our privacy practices are audited against international standards
- Cyber attacks are bigger than ever. Many groups might use sophisticated methods to gain access to an organization’s data. These attacks have become possible because we live online. This means almost every organization is digitally connected to its customers, partners, and even their employees globally.
- Traditional on-premises systems or company-owned data centers generally rely on a perimeter-based security approach. The boundary around all of the data is protected by security features. Once someone is inside that security perimeter, they are deemed trustworthy and therefore have access to everything.
- In the Internet of Things era, where everything is connected through sensors that collect data, everything is a node on a network. When everything is a node, each node becomes an entry point. So what are the common cybersecurity threats?
    - Criminal Attack
        - Phishing attackers do research to gather information about you or anyone in your organization, then craft highly targeted emails to trick these people into thinking that the messages are genuine. These people are scammed into downloading malicious attachments, giving up their passwords, or sharing sensitive data.
    - Physical damage
        - This means that organizations can still be responsible for data losses even when there is damage to the physical hard disk, there are power losses, or natural disasters such as floods, fires, and earthquakes.
    - Malware, viruses, and ransomware attacks
        - Data can be lost, damaged, or destroyed by viruses or malware. Alternatively, a set of files can be rendered unavailable to its intended users via ransomware until the ransom amount is paid.
    - Unsecured third-party systems
        - Although third-party systems are often used to address common business needs, without adequate security measures and regular checks, these systems can pose a threat to data security.
    - Lack of expert knowledge
        - At the rate that technology is changing, investing in the right expertise to assess, develop, implement, and maintain data security plans is essential for businesses to stay ahead of potential data security threats.
- When an organization manages its data in its own data centers, that organization is then responsible for all aspects of its security.
- The advantage of using cloud technology is that the responsibility to secure data is shared between a business and the cloud provider.
- When an organization adopts the cloud, the cloud service provider typically becomes the data processor. The organization is the data controller.
- Google Clouds multilayer approach to security
    - Hardware
        - Google designs its own servers, its storage, and its networking gear. It manufactures almost all of its own hardware, and third parties never see the overall process. The hardware is housed in these high-security data centers that are located around the world.
        - New server builds have a chip, called Titan, embedded. Titan checks a machine for integrity every time it boots up.
    - Software
        - The Titan microcontroller continues to verify the operating systems and the rest of the deployed software stack. The server is not allowed onto the network and it holds zero data until its health is confirmed.
    - Storage
        - Storage is closely connected to the idea of data encryption at rest. Encryption at rest protects data when it is stored on physical media. ALL data at rest is also encrypted by default to help guard against unauthorized access.
        - The defense-in-depth process for storing data in Google Cloud is:
            - Data is broken into many pieces in memory.
            - These pieces, or “chunks”, are encrypted with their own data encryption key or ‘DEK’.
            - These DEKs are then encrypted a second time with key encryption key or ‘KEK’.
            - Encrypted chunks and wrapped KEKs are distributed across Google’s infrastructure.
        - In the unlikely event that someone compromises an encryption key, they could only access one tiny piece of data, which, without all of the other pieces, would be unreadable.
    - Identity
        - Instead of relying on the traditional perimeter approach to security, Google Cloud operates a zero-trust model. This means that every user and every machine that tries to access data or services must strongly authenticate identity at each stage for each file.
    - Network
        - Anyone accessing the cloud does so via a network. Encryption in transit protects data as it moves across a network. Multiple layers of defense are in place to help protect customers against network attacks, like DDoS attacks.
    - Operations
        - At Google, a global operations team of more than 900 security experts monitor the system 24 hours a day, 365 days a year. Their role is to detect attacks and other issues and to respond to them.

![Untitled](Cloud%20Digi%2068a8f/Untitled%2012.png)

- IT teams need to have a complete understanding of who can access what data. Wherever possible, they need to establish granular access policies. They need to define who can do what, and on what cloud resource.
- An Identity Access Management policy, or IAM policy, is made of three parts:
    - Who
        - The “who” part of an IAM policy can be a Google account, a Google group, a service account, or a Google Workspace or Cloud Identity domain.
    - can do what
        - Three kinds of roles in Cloud IAM
            - Primitive
            - Predefined
            - Custom
        - The “can do what” part is defined by an IAM role. If you’re a viewer on a given resource, you can examine it, but not change its state. If you’re an editor, you can do everything a viewer can do plus change its state. And if you’re an owner, you can do everything an editor can do plus manage roles and permissions on the resource.
        - Google Cloud recommends using a “least-privilege” model, in which each person in your organization is given the minimal amount of privilege needed to do their job.
    - on which resource
        - An organization can easily map job functions within the organization to specific groups. Each group can then be given specific roles for specific resources. Users get access only to what they need to do their job, and admins can grant default permissions to entire groups of users.
        - In the cloud environment, a project is a basis for enabling and using Google Cloud capabilities, like managing APIs, enabling billing, adding and removing collaborators, and enabling other Google (or Alphabet) services.
        - Resource Hierarchy
            - Resource hierarchy refers to the way your IT team can organize your business’ Google Cloud environment and how that service structure maps to your organization's actual structure. For example, by teams or by projects or by both. With a resource hierarchy, IT teams can manage access and permissions for groups of related resources.
            - Everything managed in Google Cloud is under a domain and an organization. The domain is handled through Cloud Identity and helps manage user profiles. The organization is managed through the Cloud Console and lets administrators see and control Google Cloud resources and permissions.
            - Projects belong to the organization rather than the user that created them. Projects are used for grouping Google Cloud resources like Cloud Storage buckets. It can inherit permissions from any folders above it as well as from the organization at the top, making it easy to set organization-wide rules and policies that cascade down and are enforced throughout the hierarchy.

---

### Module 3 - Monitoring Cl9oud IT Services and Operations

- “Page under construction” or “503 Service Unavailable” messages
    - These messages may be the result of planned maintenance when a company wants to release updates to their website, so they need to take their service offline while changes are being implemented. Or the message on the screen may be the result of an unexpected system failure, and engineers are trying to fix the problem as quickly as possible.
    - If a service disruption happens unexpectedly, this may be the result of a team structure issue where developers and operators are working in silos. The structure of these teams restricts collaboration and obscures accountability.
    - Developers are responsible for writing code for systems and applications, and operators are responsible for ensuring that those systems and applications operate reliably.
    - Developers are expected to be agile. Their aim is to release new functions frequently, increase core business value with new features, and release fixes fast for an overall better user experience. In contrast, operators are expected to keep systems stable, and so they often prefer to work more slowly to ensure reliability and consistency.
- For organizations to thrive in the cloud, they’ll need to adapt their IT operations:
    - Adjust expectations for service reliability
    - Adopt best practices from DevOps and SRE
- Reliability
    - In order to roll out updates, operators have to take a system offline. Ensuring 100% service availability is also incredibly expensive for any business. This means that at some point the marginal cost of reliability exceeds the marginal value of reliability.
    - Cloud providers use standard practices to define and measure service availability for customers:
        - Service Level Agreement
            - A contractual commitment between the cloud service provider and the customer. The SLA provides the baseline level for the quality, availability, and reliability of that service. If the baseline service is not met by the provider, end users and end customers would be affected. The cloud provider would incur a cost usually paid out to the customer.
        - Service level objectives
            - A key element within the SLA; the goal for the cloud service performance level, shared between the cloud provider and a customer. If the service performance meets or exceeds the SLO, it means that end-users, customers, and internal stakeholders are all happy.
        - Service level indicators
            - A measure of the service provided. SLIs often include reliability, latency (which means delays in the system), and errors.
    - The error budget is typically the space between the SLA and the SLO. This error budget gives developers clarity into how many failed fixes they can attempt without affecting the end-user experience.
- DevOps
    - A philosophy that seeks to create a more collaborative and accountable culture within developer and operations teams. The philosophy highlights how IT teams can operate, but doesn’t give explicit guidance on how an organization should implement practices to be successful.
    - Five objectives of DevOps
        - Reduce silos
            - SRE emphasizes shared ownership of production between developers and operations. Together, they define service level objectives or SLOs, calculate error budgets, determine reliability, and order work priorities.
        - Accept failure as normal
            - SREs believe that accepting failure as normal helps to build an iterative, collaborative culture. One way this is done is by holding a blameless “lessons learned” discussion after an incident occurs.
        - Implement gradual change
            - When implementing gradual changes, SREs aims to reduce the cost of failure by rolling out changes to a small percentage of users before making them generally available. This promotes more prototyping and launching iteratively.
        - Leverage tooling automation
            - In order to leverage tooling and automation, SREs focus on toil automation. In software engineering, toil is a type of work that is tied to running a production service. Toil automation, therefore, reduces the amount of manual, repetitive work.
        - Measure everything
            - ‘Measure everything’ means tracking everything related to toil, reliability, and the health of their systems.
    - To foster these practices, organizations need a culture of goal setting, transparency, and data-driven decision-making. They also need the tools to monitor their cloud environment, and to identify whether they are meeting their service level objectives.
- Site Reliability Engineering
    - A discipline that applies aspects of software engineering to operations. The goals of SRE are to create ultra-scalable and highly reliable software systems.
    - SRE shifts the mindset from ‘100% availability’ to 99.99% or 99.999% availability. This means that updates are pushed out iteratively and continually, but only require seconds or minutes of downtime.
- The tools included in Google Cloud’s operations suite fall into two major categories:

Operational-focused tools

- Cloud Monitoring
    - Cloud Monitoring is the foundation for Site Reliability Engineering because it provides visibility into the performance, uptime, and overall health of cloud-powered applications.
- Cloud Logging
    - A text file where applications, including the operating system, write events. Log files make it easier for developers, DevOps, and System Admins to get insights and identify the root cause of issues within applications and the infrastructure.
    - Google Cloud Logging is a fully managed service that performs at scale and can ingest application and system log data, as well as custom log data from Google Kubernetes Engine, or GKE, environments, Virtual Machines, and Google Cloud services.
    - All Google Cloud services, from Google Kubernetes Engine, to BigQuery, to Cloud Spanner, stream metrics and logs into the Google Cloud Logging and Cloud Monitoring components.
- Error Reporting
- Service Monitoring

Application performance management tools

- Cloud Debugger
    - Cloud Debugger helps monitor application performance. IT teams can inspect the state of a running application in real-time, without stopping or slowing it down. This means that end-users are not affected while a developer searches the source code. IT teams can use it to understand the behavior of their code in production and analyze its state to find those hard-to-find bugs.
- Cloud Trace
    - Cloud Trace is another Google Cloud solution for monitoring application performance. It is a distributed tracing system that helps developers debug or fix and optimize their code.
- Cloud Profiler